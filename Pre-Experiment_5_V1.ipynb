{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Experiment 5: Implementation of MSDS 458 Assignment 3 Code (RNN, LSTM, and 1D-CNN Models) for Text Classifiction Applied to the Golf Course Reviews Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**i. Import the necessary libraries for the experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necesary libraries\n",
    "import datetime\n",
    "from packaging import version\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# %pip install tensorflow_datasets\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plots to appear inline\n",
    "%matplotlib inline\n",
    "# Set the default precision for numpy\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Enable display of multiple outputs per Jupyter Notebook cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ii. Load in the golf course reviews dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "file_path = \"top_and_non_golf_course_reviews.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Examine the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>course_name</th>\n",
       "      <th>label</th>\n",
       "      <th>location</th>\n",
       "      <th>architect</th>\n",
       "      <th>year_built</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_author</th>\n",
       "      <th>file_name</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pine Valley, NJ</td>\n",
       "      <td>George Crump / Harry S. Colt</td>\n",
       "      <td>1918</td>\n",
       "      <td>PINE VALLEY GOLF CLUB - 19 POINTS</td>\n",
       "      <td>David Jones</td>\n",
       "      <td>rev01_pine_valley_1</td>\n",
       "      <td>There’s not much point trying to do a hole-by-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pine Valley, NJ</td>\n",
       "      <td>George Crump / Harry S. Colt</td>\n",
       "      <td>1918</td>\n",
       "      <td>Pine Valley Golf Club (Clementon, New Jersey)</td>\n",
       "      <td>Bill Satterfield</td>\n",
       "      <td>rev02_pine_valley_2</td>\n",
       "      <td>What to Expect:  Pine Valley is the finest gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cypress Point</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pebble Beach, CA</td>\n",
       "      <td>Alister MacKenzie</td>\n",
       "      <td>1928</td>\n",
       "      <td>CYPRESS POINT REVIEW</td>\n",
       "      <td>Graylyn Loomis</td>\n",
       "      <td>rev03_cypress_point_1</td>\n",
       "      <td>“No one but a poet should be allowed to write ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cypress Point</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pebble Beach, CA</td>\n",
       "      <td>Alister MacKenzie</td>\n",
       "      <td>1928</td>\n",
       "      <td>Cypress Point Golf Club (Pebble Beach, Califor...</td>\n",
       "      <td>Bill Satterfield</td>\n",
       "      <td>rev04_cypress_point_2</td>\n",
       "      <td>What to Expect:  I don't even feel worthy to w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shinnecock Hills</td>\n",
       "      <td>top100</td>\n",
       "      <td>Southampton, NY</td>\n",
       "      <td>William Flynn</td>\n",
       "      <td>1931</td>\n",
       "      <td>Review: Shinnecock Hills Golf Club</td>\n",
       "      <td>Andrew Harvie</td>\n",
       "      <td>rev05_shinnecock_1</td>\n",
       "      <td>There’s not many courses as acclaimed, sought ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id       course_name   label          location  \\\n",
       "0          1       Pine Valley  top100   Pine Valley, NJ   \n",
       "1          2       Pine Valley  top100   Pine Valley, NJ   \n",
       "2          3     Cypress Point  top100  Pebble Beach, CA   \n",
       "3          4     Cypress Point  top100  Pebble Beach, CA   \n",
       "4          5  Shinnecock Hills  top100   Southampton, NY   \n",
       "\n",
       "                      architect  year_built  \\\n",
       "0  George Crump / Harry S. Colt        1918   \n",
       "1  George Crump / Harry S. Colt        1918   \n",
       "2             Alister MacKenzie        1928   \n",
       "3             Alister MacKenzie        1928   \n",
       "4                 William Flynn        1931   \n",
       "\n",
       "                                        review_title     review_author  \\\n",
       "0                  PINE VALLEY GOLF CLUB - 19 POINTS       David Jones   \n",
       "1      Pine Valley Golf Club (Clementon, New Jersey)  Bill Satterfield   \n",
       "2                               CYPRESS POINT REVIEW    Graylyn Loomis   \n",
       "3  Cypress Point Golf Club (Pebble Beach, Califor...  Bill Satterfield   \n",
       "4                 Review: Shinnecock Hills Golf Club     Andrew Harvie   \n",
       "\n",
       "               file_name                                        review_text  \n",
       "0    rev01_pine_valley_1  There’s not much point trying to do a hole-by-...  \n",
       "1    rev02_pine_valley_2  What to Expect:  Pine Valley is the finest gol...  \n",
       "2  rev03_cypress_point_1  “No one but a poet should be allowed to write ...  \n",
       "3  rev04_cypress_point_2  What to Expect:  I don't even feel worthy to w...  \n",
       "4     rev05_shinnecock_1  There’s not many courses as acclaimed, sought ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>course_name</th>\n",
       "      <th>label</th>\n",
       "      <th>location</th>\n",
       "      <th>architect</th>\n",
       "      <th>year_built</th>\n",
       "      <th>review_title</th>\n",
       "      <th>review_author</th>\n",
       "      <th>file_name</th>\n",
       "      <th>review_text</th>\n",
       "      <th>top100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pine Valley, NJ</td>\n",
       "      <td>George Crump / Harry S. Colt</td>\n",
       "      <td>1918</td>\n",
       "      <td>PINE VALLEY GOLF CLUB - 19 POINTS</td>\n",
       "      <td>David Jones</td>\n",
       "      <td>rev01_pine_valley_1</td>\n",
       "      <td>There’s not much point trying to do a hole-by-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pine Valley</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pine Valley, NJ</td>\n",
       "      <td>George Crump / Harry S. Colt</td>\n",
       "      <td>1918</td>\n",
       "      <td>Pine Valley Golf Club (Clementon, New Jersey)</td>\n",
       "      <td>Bill Satterfield</td>\n",
       "      <td>rev02_pine_valley_2</td>\n",
       "      <td>What to Expect:  Pine Valley is the finest gol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cypress Point</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pebble Beach, CA</td>\n",
       "      <td>Alister MacKenzie</td>\n",
       "      <td>1928</td>\n",
       "      <td>CYPRESS POINT REVIEW</td>\n",
       "      <td>Graylyn Loomis</td>\n",
       "      <td>rev03_cypress_point_1</td>\n",
       "      <td>“No one but a poet should be allowed to write ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cypress Point</td>\n",
       "      <td>top100</td>\n",
       "      <td>Pebble Beach, CA</td>\n",
       "      <td>Alister MacKenzie</td>\n",
       "      <td>1928</td>\n",
       "      <td>Cypress Point Golf Club (Pebble Beach, Califor...</td>\n",
       "      <td>Bill Satterfield</td>\n",
       "      <td>rev04_cypress_point_2</td>\n",
       "      <td>What to Expect:  I don't even feel worthy to w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shinnecock Hills</td>\n",
       "      <td>top100</td>\n",
       "      <td>Southampton, NY</td>\n",
       "      <td>William Flynn</td>\n",
       "      <td>1931</td>\n",
       "      <td>Review: Shinnecock Hills Golf Club</td>\n",
       "      <td>Andrew Harvie</td>\n",
       "      <td>rev05_shinnecock_1</td>\n",
       "      <td>There’s not many courses as acclaimed, sought ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id       course_name   label          location  \\\n",
       "0          1       Pine Valley  top100   Pine Valley, NJ   \n",
       "1          2       Pine Valley  top100   Pine Valley, NJ   \n",
       "2          3     Cypress Point  top100  Pebble Beach, CA   \n",
       "3          4     Cypress Point  top100  Pebble Beach, CA   \n",
       "4          5  Shinnecock Hills  top100   Southampton, NY   \n",
       "\n",
       "                      architect  year_built  \\\n",
       "0  George Crump / Harry S. Colt        1918   \n",
       "1  George Crump / Harry S. Colt        1918   \n",
       "2             Alister MacKenzie        1928   \n",
       "3             Alister MacKenzie        1928   \n",
       "4                 William Flynn        1931   \n",
       "\n",
       "                                        review_title     review_author  \\\n",
       "0                  PINE VALLEY GOLF CLUB - 19 POINTS       David Jones   \n",
       "1      Pine Valley Golf Club (Clementon, New Jersey)  Bill Satterfield   \n",
       "2                               CYPRESS POINT REVIEW    Graylyn Loomis   \n",
       "3  Cypress Point Golf Club (Pebble Beach, Califor...  Bill Satterfield   \n",
       "4                 Review: Shinnecock Hills Golf Club     Andrew Harvie   \n",
       "\n",
       "               file_name                                        review_text  \\\n",
       "0    rev01_pine_valley_1  There’s not much point trying to do a hole-by-...   \n",
       "1    rev02_pine_valley_2  What to Expect:  Pine Valley is the finest gol...   \n",
       "2  rev03_cypress_point_1  “No one but a poet should be allowed to write ...   \n",
       "3  rev04_cypress_point_2  What to Expect:  I don't even feel worthy to w...   \n",
       "4     rev05_shinnecock_1  There’s not many courses as acclaimed, sought ...   \n",
       "\n",
       "   top100  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new label column that indicates whether the review is a top100 course or not\n",
    "df[\"top100\"] = df[\"label\"].apply(lambda x: 1 if x == \"top100\" else 0)\n",
    "\n",
    "# Examine the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_text\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf_text\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Define stopwords\u001b[39;00m\n\u001b[1;32m      5\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopwords\u001b[39m\u001b[38;5;124m'\u001b[39m, quiet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_text'"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "# Define stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "def custom_stopwords(input_text):\n",
    "    # Convert to lowercase\n",
    "    lower_text = tf_text.case_fold_utf8(input_text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = tf_text.words_and_offsets(lower_text)\n",
    "    \n",
    "    # Remove punctuation and filter stop words\n",
    "    words = tf.strings.regex_replace(words.words, r'[^\\w\\s]', '')\n",
    "    mask = tf.reduce_all(tf.not_equal(tf.expand_dims(words, -1), tf.constant(list(STOPWORDS))), axis=-1)\n",
    "    filtered_words = tf.boolean_mask(words, mask)\n",
    "    \n",
    "    # Join the words back into a string\n",
    "    return tf.strings.reduce_join(filtered_words, separator=' ', axis=-1)\n",
    "\n",
    "# Apply the custom_stopwords function to the DataFrame\n",
    "df['cleaned_review_text'] = df['review_text'].apply(lambda x: custom_stopwords(tf.constant(x)).numpy().decode())\n",
    "\n",
    "# Create and adapt TextVectorization layer\n",
    "max_tokens = None\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    standardize=custom_stopwords\n",
    ")\n",
    "\n",
    "# Convert the pandas Series to a TensorFlow dataset\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices(df['cleaned_review_text'].values)\n",
    "\n",
    "# Adapt the TextVectorization layer\n",
    "text_vectorization.adapt(text_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create training, validation, and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 70% training, 15% validation, and 15% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First split: 70% training, the remaining 30% for validation and testing\n",
    "train_df, remaining = train_test_split(df, test_size=0.3, stratify=df['top100'], random_state=42)\n",
    "\n",
    "# Second split: 50% of the remaining data for validation, the other 50% for testing\n",
    "val_df, test_df = train_test_split(remaining, test_size=0.5, stratify=remaining['top100'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Preprocess the textual data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>cleaned_review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There’s not much point trying to do a hole-by-...</td>\n",
       "      <td>there’s much point trying holebyhole guide pin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What to Expect:  Pine Valley is the finest gol...</td>\n",
       "      <td>expect pine valley finest golf course planet h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“No one but a poet should be allowed to write ...</td>\n",
       "      <td>“no one poet allowed write beauties cypress po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What to Expect:  I don't even feel worthy to w...</td>\n",
       "      <td>expect dont even feel worthy write review cypr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There’s not many courses as acclaimed, sought ...</td>\n",
       "      <td>there’s many courses acclaimed sought document...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_text  \\\n",
       "0  There’s not much point trying to do a hole-by-...   \n",
       "1  What to Expect:  Pine Valley is the finest gol...   \n",
       "2  “No one but a poet should be allowed to write ...   \n",
       "3  What to Expect:  I don't even feel worthy to w...   \n",
       "4  There’s not many courses as acclaimed, sought ...   \n",
       "\n",
       "                                 cleaned_review_text  \n",
       "0  there’s much point trying holebyhole guide pin...  \n",
       "1  expect pine valley finest golf course planet h...  \n",
       "2  “no one poet allowed write beauties cypress po...  \n",
       "3  expect dont even feel worthy write review cypr...  \n",
       "4  there’s many courses acclaimed sought document...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords', quiet=True)\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Define a function to clean the text and remove stopwords\n",
    "# def custom_stopwords(input_text):\n",
    "#     lowercase = input_text.lower()\n",
    "#     stripped_punct = tf.strings.regex_replace(lowercase\n",
    "#                                   ,'[%s]' % re.escape(string.punctuation)\n",
    "#                                   ,'')\n",
    "#     return tf.strings.regex_replace(stripped_punct, r'\\b(' + r'|'.join(STOPWORDS) + r')\\b\\s*',\"\")\n",
    "\n",
    "def custom_stopwords(input_text):\n",
    "    lowercase = input_text.lower()\n",
    "    stripped_punct = re.sub(f'[{re.escape(string.punctuation)}]', '', lowercase)\n",
    "    return ' '.join([word for word in stripped_punct.split() if word not in STOPWORDS])\n",
    "\n",
    "\n",
    "# Apply the preprocessing function to the 'review_text' column of the df DataFrame\n",
    "df['cleaned_review_text'] = df['review_text'].apply(custom_stopwords)\n",
    "\n",
    "# Display the first few rows from the DataFrame\n",
    "df[['review_text', 'cleaned_review_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mstr\u001b[39m(x))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Apply preprocessing to the review text\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_review_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_stopwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create and adapt TextVectorization layer\u001b[39;00m\n\u001b[1;32m     14\u001b[0m max_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI-DL/lib/python3.11/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI-DL/lib/python3.11/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI-DL/lib/python3.11/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/envs/AI-DL/lib/python3.11/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AI-DL/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m, in \u001b[0;36mcustom_stopwords\u001b[0;34m(input_text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_stopwords\u001b[39m(input_text):\n\u001b[0;32m----> 3\u001b[0m     lowercase \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m      4\u001b[0m     stripped_punct \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mre\u001b[38;5;241m.\u001b[39mescape(string\u001b[38;5;241m.\u001b[39mpunctuation)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, lowercase)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m stripped_punct\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m STOPWORDS])\n",
      "File \u001b[0;32m~/anaconda3/envs/AI-DL/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:260\u001b[0m, in \u001b[0;36mTensor.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    253\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolist\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    254\u001b[0m   \u001b[38;5;66;03m# TODO(wangpeng): Export the enable_numpy_behavior knob\u001b[39;00m\n\u001b[1;32m    255\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    256\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001b[39m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124m  \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "# Convert the input text to a string before applying the lower() method\n",
    "def custom_stopwords(input_text):\n",
    "    lowercase = tf.strings.as_string(input_text).lower()\n",
    "    stripped_punct = re.sub(f'[{re.escape(string.punctuation)}]', '', lowercase)\n",
    "    return ' '.join([word for word in stripped_punct.split() if word not in STOPWORDS])\n",
    "\n",
    "# Convert the input text to a string before applying the lower() method\n",
    "df['review_text'] = df['review_text'].apply(lambda x: str(x))\n",
    "\n",
    "# Apply preprocessing to the review text\n",
    "df['cleaned_review_text'] = df['review_text'].apply(custom_stopwords)\n",
    "\n",
    "# Create and adapt TextVectorization layer\n",
    "max_tokens = None\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    standardize=custom_stopwords)\n",
    "\n",
    "# Adapt the TextVectorization layer with the updated custom_stopwords function\n",
    "text_vectorization.adapt(df['cleaned_review_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
