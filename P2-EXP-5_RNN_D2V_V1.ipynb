{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5: Simple Bidirectional RNN Model with Doc2Vec Embeddings\n",
    "**(Version 1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Import the necessary libraries and modules for this experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from packaging import version\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# %pip install tensorflow_datasets\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as k\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default precision for numpy\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# Enable display of multiple outputs per Jupyter Notebook cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**2. Load in the golf course reviews dataset & create a new label column**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"top_and_non_golf_course_reviews.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a new label column that indicates whether the review is a top100 course or not\n",
    "df['top100'] = df['label'].apply(lambda x: 1 if x == 'top100' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**3. Split the dataset into training, validation, and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape: (80, 11)\n",
      "Validation Dataset Shape: (20, 11)\n",
      "Test Dataset Shape: (20, 11)\n"
     ]
    }
   ],
   "source": [
    "train_df, remaining = train_test_split(df, test_size=0.33, stratify=df['top100'], random_state=42)\n",
    "val_df, test_df = train_test_split(remaining, test_size=0.5, stratify=remaining['top100'], random_state=42)\n",
    "\n",
    "# Check the shape of the training, validation, and test sets\n",
    "print(f\"Training Dataset Shape: {train_df.shape}\")\n",
    "print(f\"Validation Dataset Shape: {val_df.shape}\")\n",
    "print(f\"Test Dataset Shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**4. Preprocess the text data from the 'review_text' column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Remove stopwords (using the NLTK library)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing function to the 'review_text' column of the df DataFrame\n",
    "train_df['preprocessed_text'] = train_df['review_text'].apply(preprocess_text)\n",
    "val_df['preprocessed_text'] = val_df['review_text'].apply(preprocess_text)\n",
    "test_df['preprocessed_text'] = test_df['review_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**5. Convert the preprocessed text data into a list of tagged documents (Doc2Vec format)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tagged_documents(df):\n",
    "    \"\"\"\n",
    "    Create a list of tagged documents from the 'preprocessed_text' column of the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        df (pandas.DataFrame): The DataFrame containing the 'preprocessed_text' column.\n",
    "\n",
    "    Returns:\n",
    "        List[gensim.models.doc2vec.TaggedDocument]: A list of TaggedDocument objects, where each TaggedDocument represents a document with its corresponding tag (index).\n",
    "    \"\"\"\n",
    "    return [TaggedDocument(words=text.split(), tags=[str(i)]) for i, text in enumerate(df['preprocessed_text'])]\n",
    "\n",
    "tagged_documents = create_tagged_documents(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**6. Train the Doc2Vec model and generate the embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=100, min_count=2, epochs=40)\n",
    "model.build_vocab(tagged_documents)\n",
    "model.train(tagged_documents, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Define a function to generate the embeddings for the split dataframes\n",
    "def get_doc2vec_embeddings(model, df):\n",
    "    return np.array([model.infer_vector(text.split()) for text in df['preprocessed_text']])\n",
    "\n",
    "# Generate the embeddings for the training, validation, and test sets\n",
    "train_embeddings = get_doc2vec_embeddings(model, train_df)\n",
    "val_embeddings = get_doc2vec_embeddings(model, val_df)\n",
    "test_embeddings = get_doc2vec_embeddings(model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**7. Create Two Layer Simple Bidirectional RNN Model with Doc2Vec Embeddings**\n",
    "\n",
    "- Two Bidirectional RNN layers (64 units and 32 units)\n",
    "- ReLu activation function\n",
    "- RMSprop optimizer (learning rate = 0.001)\n",
    "- Vocabulary size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the unidirectional RNN model\n",
    "inputs = tf.keras.Input(shape=(100,), name=\"input\")\n",
    "x = tf.keras.layers.Reshape((100, 1))(inputs)\n",
    "x = tf.keras.layers.Bidirectional(layers.SimpleRNN(units=64, activation='relu', return_sequences=True, name=\"Bidirectional_RNN_1\"))(x)\n",
    "x = tf.keras.layers.Bidirectional(layers.SimpleRNN(units=32, activation='relu', name=\"Bidirectional_RNN_2\"))(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"Two_Layer_RNN_D2V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n",
    "**8. Compile the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Two_Layer_RNN_D2V\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Two_Layer_RNN_D2V\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input (\u001b[38;5;33mInputLayer\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │         \u001b[38;5;34m8,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m10,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,817</span> (73.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,817\u001b[0m (73.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,817</span> (73.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,817\u001b[0m (73.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**9. Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.4984 - loss: 0.7537 - val_accuracy: 0.5500 - val_loss: 0.6924\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6477 - loss: 0.6294 - val_accuracy: 0.5000 - val_loss: 0.6762\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6977 - loss: 0.5735 - val_accuracy: 0.6000 - val_loss: 0.6601\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8250 - loss: 0.5324 - val_accuracy: 0.5500 - val_loss: 0.6603\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8047 - loss: 0.4791 - val_accuracy: 0.5500 - val_loss: 0.6407\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8828 - loss: 0.4203 - val_accuracy: 0.5500 - val_loss: 0.6202\n",
      "Training Time: 2.0062851905822754 seconds\n"
     ]
    }
   ],
   "source": [
    "# Clear any existing models in memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Define the callbacks for the model training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"EXP_5_RNN_D2V.keras\", save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_embeddings, train_df['top100'],\n",
    "                    validation_data=(val_embeddings, val_df['top100']),\n",
    "                    epochs=20,\n",
    "                    callbacks=callbacks)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the training time\n",
    "print(f\"Training Time: {training_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**10. Evaluate the model on the test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 0.6500 - loss: 0.6495\n",
      "Test Loss: 0.6494666337966919, Test Accuracy: 0.6499999761581421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n1.2.2 Extract the training history and add all evaluation metrics into a history DataFrame\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXP</th>\n",
       "      <th>Model</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>RNN w/ Doc2Vec Embeddings</td>\n",
       "      <td>0.425126</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.620164</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.649467</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.006285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EXP                      Model  Training Loss  Training Accuracy  \\\n",
       "0    5  RNN w/ Doc2Vec Embeddings       0.425126              0.875   \n",
       "\n",
       "   Validation Loss  Validation Accuracy  Test Loss  Test Accuracy  \\\n",
       "0         0.620164                 0.55   0.649467           0.65   \n",
       "\n",
       "   Training Time  \n",
       "0       2.006285  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the best model\n",
    "model = tf.keras.models.load_model(\"EXP_5_RNN_D2V.keras\")\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_embeddings, test_df['top100'])\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Get the training loss, validation loss, training accuracy, and validation accuracy from the history object\n",
    "training_loss = history.history['loss'][-1] # the -1 index gets the last epoch\n",
    "validation_loss = history.history['val_loss'][-1]\n",
    "training_accuracy = history.history['accuracy'][-1]\n",
    "validation_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "\"\"\"\n",
    "1.2.2 Extract the training history and add all evaluation metrics into a history DataFrame\n",
    "\"\"\"\n",
    "# Extract the training history into a pandas DataFrame\n",
    "history_df = pd.DataFrame({\n",
    "    'EXP': [5],\n",
    "    'Model': ['RNN w/ Doc2Vec Embeddings'],\n",
    "    'Training Loss': [training_loss],\n",
    "    'Training Accuracy': [training_accuracy],\n",
    "    'Validation Loss': [validation_loss],\n",
    "    'Validation Accuracy': [validation_accuracy],\n",
    "    'Test Loss': [test_loss],\n",
    "    'Test Accuracy': [test_accuracy],\n",
    "    'Training Time': [training_time]\n",
    "})\n",
    "\n",
    "# Inspect the history DataFrame\n",
    "history_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
